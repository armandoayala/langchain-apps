Embeddings are generated by AI models (such as Large Language Models) and have a large number of attributes or features, making their representation challenging to manage. In the context of AI and machine learning, these features represent different dimensions of the data that are essential for understanding patterns, relationships, and underlying structures.

That is why we need a specialized database designed specifically for handling this type of data. Vector databases fulfill this requirement by offering optimized storage and querying capabilities for embeddings. Vector databases have the capabilities of a traditional database that are absent in standalone vector indexes and the specialization of dealing with vector embeddings, which traditional scalar-based databases lack.

The challenge of working with vector embeddings is that traditional scalar-based databases can’t keep up with the complexity and scale of such data, making it difficult to extract insights and perform real-time analysis. That’s where vector databases come into play — they are intentionally designed to handle this type of data and offer the performance, scalability, and flexibility you need to make the most out of your data.

How does a vector database work?
We all know how traditional databases work (more or less) — they store strings, numbers, and other types of scalar data in rows and columns. On the other hand, a vector database operates on vectors, so the way it’s optimized and queried is quite different.

In traditional databases, we are usually querying for rows in the database where the value usually exactly matches our query. In vector databases, we apply a similarity metric to find a vector that is the most similar to our query.

A vector database uses a combination of different algorithms that all participate in Approximate Nearest Neighbor (ANN) search. These algorithms optimize the search through hashing, quantization, or graph-based search.

These algorithms are assembled into a pipeline that provides fast and accurate retrieval of the neighbors of a queried vector. Since the vector database provides approximate results, the main trade-offs we consider are between accuracy and speed. The more accurate the result, the slower the query will be. However, a good system can provide ultra-fast search with near-perfect accuracy.

Here’s a common pipeline for a vector database:


Indexing: The vector database indexes vectors using an algorithm such as PQ, LSH, or HNSW. This step maps the vectors to a data structure that will enable faster searching.
Querying: The vector database compares the indexed query vector to the indexed vectors in the dataset to find the nearest neighbors (applying a similarity metric used by that index)
Post Processing: In some cases, the vector database retrieves the final nearest neighbors from the dataset and post-processes them to return the final results. This step can include re-ranking the nearest neighbors using a different similarity measure.
With a vector database, we can add advanced features to our AIs, like semantic information retrieval, long-term memory, and more. The diagram above gives us a better understanding of the role of vector databases in this type of application.

Why Use a Vector Database?
Vector search in production is the most common reason to use a vector database. Vector search compares the similarity of multiple objects to a search query or subject item. In order to find similar matches, you convert the subject item or query into a vector using the same ML embedding model used to create your vector embeddings. The vector database compares the similarity of these objects to find the closest matches, providing accurate results while eliminating irrelevant results that traditional search technology might have returned.

Let’s look at some common use cases for vector search:

1. Semantic search
Searching text and documents can generally be done in two ways. Lexical search looks for patterns and exact word or string matches, while semantic search uses the meaning of your search query or question and puts it into context. Vector databases store and index vector embeddings from Natural Language Processing models to understand the meaning and context of strings of text, sentences, and whole documents for more accurate and relevant search results.

Using natural language queries to find relevant results is a better experience and allows users to find what they need more quickly without having to know specifics about how the data is classified.

2. Similarity search for images, audio, video, JSON, and other forms of unstructured data
Images, audio, video, and other unstructured datasets can be very challenging to classify and store in a traditional database. This often requires keywords, descriptions, and metadata to be manually applied to each object. The way one individual classifies one of the complex data objects may not be obvious to another. As a result, searching for complex data can be very hit and miss. This approach requires the searcher to understand something about how the data is structured and construct queries that match the original data model.

3. Ranking and recommendation engines
Vector databases are a great solution for powering ranking and recommendation engines. For online retailers, they can be used to suggest items similar to past purchases or a current item the customer is researching. Streaming media services can apply a user’s song ratings to create perfectly matched recommendations tailored to the individual rather than relying on collaborative filtering or popularity lists.

The ability to find similar items based on nearest matches makes vector databases ideal for offering relevant suggestions, and can easily rank items based on similarity scores.

4. Deduplication and record matching
Another use case for vector similarity search is record matching and deduplication. Using the similarity service to find near-duplicate records can be used in a wide range of applications. Consider an application that removes duplicate items from a catalog to make it far more usable and relevant.

5. Anomaly detection
As good as vector databases are in finding similar objects, they can also find objects that are distant or dissimilar from an expected result. These anomalies are valuable in applications used for threat assessment, fraud detection, and IT Operations. It’s possible to identify the most relevant anomalies for further analysis without overwhelming resources with a high rate of false alarms.

Popular Vector Databases:
Pinecone
Pinecone is one such vector database that is widely accepted across the industry for addressing challenges such as complexity and dimensionality. Pinecone is a cloud-native vector database that handles high-dimensional vector data. The core underlying approach for Pinecone is based on the Approximate Nearest Neighbor (ANN) search that efficiently locates faster matches and ranks them within a large dataset.

Some of the key features of Pinecone include:

Highly scalable: Pinecone can handle billions of high-dimensional vectors and scale horizontally, making it suitable for even the most demanding machine learning workloads.
Real-time data ingestion: Pinecone supports real-time data ingestion, allowing you to store and index new data as it becomes available without any downtime.
Low-latency search: Pinecone’s advanced indexing algorithms ensure that nearest neighbor queries and similarity search operations are performed with low latency, providing fast and accurate results.
Easy integration: Pinecone’s API is designed to be simple and intuitive, making it easy to integrate with your existing machine learning workflows and data pipelines.
Fully managed service: Pinecone is a fully managed platform, which means you don’t have to worry about infrastructure management or maintenance, allowing you to focus on developing and deploying your machine learning applications.
Weavite
Weaviate is a vector database and search engine. It is a low-latency vector search engine that supports various media types(text, images, etc.). Weaviate uses machine learning to vectorize and store data and find responses to natural language questions. It includes semantic search, Question-Answer Extraction, Classification, and Customizable Models (PyTorch/TensorFlow/Keras). You may also use Weaviate to scale up your custom machine learning models in production.

Weaviate stores both media (text, images. etc.)objects and their corresponding vectors, allowing for combining vector search with structured filtering with the fault-tolerance of a cloud-native database. Weaviate search can perform through different methods such as GraphQL, REST, and various language clients. Python, Javascript, Go, and Go are popular programming languages that support Weaviate clients.

Nowadays, Weaviate is used by software engineers as an ML-first database for their applications, Data engineers to use a vector database built up from the ground with ANN at its core, Data scientists to deploy their search applications with MLOps.

Key Features of Weaviate:

Fast queries — In less than 100 milliseconds, Weaviate runs a 10 closest neighbour (NN) search over millions of items.

Different media support — Use State-of-the-Art AI model inference (e.g. Transformers) for Images, Text, etc.

Combining scalar and vector search — Weaviate saves both your objects and your vectors, ensuring that retrieval is always quick. A third-party object storage system is not required.

Horizontal scalability– Weaviate can scale horizontally in production depending on the use case.

Graph-like connections — Make graph-like connections between data items to mimic real-life connections between the data points. GraphQL is used to traverse those connections.

Milvus
Milvus is an open-source vector database that provides users with a highly efficient and scalable solution for storing, managing, and searching large-scale, high-dimensional data. It was designed with the specific goal of meeting the rapidly growing demand for advanced data analytics and machine learning applications, which require fast and accurate computation of large amounts of complex data. Milvus can be used in a variety of industries, including finance, e-commerce, healthcare, and more. In this article, we will take a closer look at Milvus and its key features, use cases, and benefits.

Key Features of Milvus:

Milvus is a highly scalable and flexible database that supports a wide range of vector data types, including image, audio, and text data. Its key features include:

Fast and Efficient: Milvus can handle large amounts of vector data with low latency and high throughput. It uses state-of-the-art algorithms and techniques to optimize storage and retrieval speed, making it ideal for real-time applications that require fast response times.

Scalable: Milvus is designed to scale horizontally, allowing users to add new nodes to their cluster as their data grows. This enables users to achieve high performance and scalability even with massive datasets.

Search and Similarity: Milvus provides a powerful search and similarity query engine that allows users to search for similar vectors within their dataset. This is especially useful for applications like image and facial recognition, natural language processing, and recommendation systems.

Multiple Interfaces: Milvus supports multiple programming interfaces, including Python, Java, and Go, making it easy to integrate with existing data analytics and machine learning tools.

FAISS
The science behind Faiss is described in detail here. With Faiss, the idea is that a vector may be convert into something more like the text that we are accustomed to searching — a sort of code word. Once we have this code word, then the idea is to use standard upside-down indexing techniques to retrieve similar results. The results may be reranked based on this approximate set of results, using exact vector comparisons.
